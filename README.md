ğŸ›ï¸ PredicciÃ³n de IntenciÃ³n de Compra a partir de Clickstream (E-Shop 2008)

Este proyecto desarrolla un proceso completo de Machine Learning aplicado a datos de navegaciÃ³n (clickstream) para predecir si una sesiÃ³n de usuario visitarÃ¡ la pÃ¡gina de Ofertas (Sale) en un e-commerce de ropa.

Incluye:

Limpieza y transformaciÃ³n del log de clicks

ConstrucciÃ³n de un dataset a nivel sesiÃ³n

Feature engineering evitando data leakage

Entrenamiento de 4 modelos base

ComparaciÃ³n de mÃ©tricas

OptimizaciÃ³n con Optuna

Interpretabilidad del modelo

RecomendaciÃ³n de negocio basada en datos

ğŸš€ Objetivo del Proyecto

Predecir si un usuario visitarÃ¡ la pÃ¡gina de ofertas (page 1 = 4), identificando comportamiento de "buscadores de descuentos". Este insight permite:

Activar personalizaciÃ³n en tiempo real

Mejorar campaÃ±as de remarketing

Incrementar las conversiones hacia productos en descuento

Entender patrones de navegaciÃ³n Ãºtiles para el Ã¡rea de marketing

ğŸ“‚ Estructura del Proyecto
ğŸ“¦ e-commerce-clickstream-ml
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ e-shop clothing 2008.csv
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ clickstream_analysis.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ modeling.py
â”‚   â”œâ”€â”€ optuna_tuning.py
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ plots/
â”‚   â”œâ”€â”€ metrics_barplot.png
â”‚   â”œâ”€â”€ xgboost_vs_optuna.png
â”‚
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt

ğŸ§¹ 1. Preprocesamiento y Feature Engineering

El dataset original estÃ¡ a nivel click, por lo que se transforma a nivel sesiÃ³n, generando features agregadas:

total_clicks

avg_price_seen

max_price_seen

distinct_products

countries

main_category_mode

Target
Visited_Sale_Page = 1 si la sesiÃ³n visitÃ³ la categorÃ­a 4 (sale)

PrevenciÃ³n de Data Leakage

Antes de agregar features se excluyen los clicks donde page 1 = 4.

ğŸ¤– 2. Modelos Entrenados

Modelos evaluados:

Logistic Regression

Decision Tree

Random Forest

XGBoost

Pipeline usado en todos:

ColumnTransformer

Escalado

ImputaciÃ³n

OneHotEncoding

ğŸ“Š 3. ComparaciÃ³n de Resultados
Modelo	Accuracy	F1	ROC-AUC	Precision	Recall
Logistic Regression	0.678	0.224	0.654	0.579	0.138
Decision Tree	0.654	0.358	0.542	0.471	0.289
Random Forest	0.621	0.406	0.575	0.427	0.388
XGBoost	0.613	0.497	0.643	0.439	0.572
XGBoost Optuna	0.622	0.533	0.669	0.454	0.646

ğŸ“Œ Modelo ganador: XGBoost optimizado con Optuna.

ğŸ”§ 4. OptimizaciÃ³n con Optuna

HiperparÃ¡metros optimizados:

n_estimators

max_depth

learning_rate

subsample

colsample_bytree

min_child_weight

gamma

ValidaciÃ³n cruzada con:

StratifiedKFold(n_splits=3)


MÃ©trica de objetivo:

F1 Score

ğŸ§© 5. Importancia de Variables (XGBoost)

Top 3 factores:

distinct_products â€“ Usuarios que comparan mÃ¡s productos tienden a visitar ofertas.

main_category_mode_3 â€“ La categorÃ­a skirts tiene mayor probabilidad de generar visitas a Sale.

total_clicks â€“ Sesiones muy activas muestran mÃ¡s intenciÃ³n de buscar descuentos.

ğŸ’¼ 6. RecomendaciÃ³n de Negocio

Mostrar un banner dinÃ¡mico de â€œOfertasâ€
para usuarios que navegan muchos productos distintos.

CampaÃ±as especÃ­ficas para usuarios interesados en â€œskirtsâ€
ya que muestran mayor sensibilidad al precio.

Activar mensajes contextuales en sesiones muy activas
sugiriendo ofertas relevantes cuando detecten alto engagement.

Estas acciones permiten guiar a usuarios con intenciÃ³n alta hacia ofertas, mejorando conversiÃ³n y experiencia.

ğŸ§ª 7. Requisitos
pandas
numpy
scikit-learn
xgboost
optuna
matplotlib
seaborn


InstalaciÃ³n:

pip install -r requirements.txt

â–¶ï¸ 8. EjecuciÃ³n
python src/preprocessing.py
python src/modeling.py
python src/optuna_tuning.py


O desde el notebook:

notebooks/clickstream_analysis.ipynb

ğŸŒ± 9. PrÃ³ximos Pasos

AÃ±adir interpretabilidad con SHAP

Probar LightGBM como baseline adicional

Crear API con FastAPI para scoring

Agregar monitoreo de modelo

Si quieres, puedo generarte ahora:

una versiÃ³n en inglÃ©s,

una versiÃ³n mÃ¡s minimalista,

o una versiÃ³n estilo profesional corporativo.
